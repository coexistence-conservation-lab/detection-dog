---
title: "Evaluation of detection dog"
author: "Shoshana Rapley"
date: "10 April 2025"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: true
    theme: cerulean
    highlight: pygments
editor_options:
  chunk_output_type: console
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding=encoding, output_file=file.path(dirname(inputFile), 'tutorial.html')) })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=TRUE)

pacman::p_load(broom, caret, ggbeeswarm2, plotrix, janitor, pROC, pwr, readxl, tidyverse)
```

# Introduction

# Power Analysis

## Dog only 

How many trials needed to determine dog performs better than sensitivity 0.5? Sensitivity at which the dog is a worthwhile approach will depend on the application. For some purposes, such as medical detection or law enforcement, sensitivity may need to be >0.9. Whereas other applications, such as detection of scats, missing some and a sensitivity of 0.5 may be appropriate. 

```{r}
# Function to calculate required sample size for proportion test
dog_sensitivity_power <- function(
  target_sensitivity = 0.9,   # Predicted sensitivity (true positive rate)
  null_sensitivity = 0.5,     # Null hypothesis value 
  power = 0.8,               # Desired power
  alpha = 0.05,              # Significance level
  alternative = "greater"    # One sided test
) {
  
  # Effect size calculation (h) for proportion test
  h <- ES.h(p1 = target_sensitivity, p2 = null_sensitivity)
  
  # Calculate required sample size using pwr.p.test
  result <- pwr.p.test(h = h, 
                     sig.level = alpha, 
                     power = power,
                     alternative = alternative)
  
  # Return sample size (rounded up)
  return(ceiling(result$n))
}

# Create a function to explore different sensitivity scenarios
sensitivity_scenarios <- function(
  sensitivities = seq(0.7, 1, by = 0.05),
  null_values = c(0.5),
  power_values = c(0.8),
  alpha = 0.05
) {
  
  # Create a grid of all combinations
  scenarios <- expand_grid(
    target_sensitivity = sensitivities,
    null_sensitivity = null_values,
    power = power_values,
    alpha = alpha
  )
  
  # Calculate required sample size for each combination
  scenarios <- scenarios %>%
    rowwise() %>%
    mutate(sample_size = dog_sensitivity_power(
      target_sensitivity = target_sensitivity,
      null_sensitivity = null_sensitivity,
      power = power,
      alpha = alpha
    )) %>%
    ungroup()
  
  return(scenarios)
}

# Generate scenarios
scenarios <- sensitivity_scenarios()

# Plot
ggplot(scenarios, 
       aes(x = target_sensitivity, y = sample_size, label  = sample_size)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_text(hjust = -1, vjust = -0.1)+
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Required Sample Size for Detection Dog Sensitivity Testing",
    subtitle = "Compared to sensitivity 0.5",
    x = "Target Sensitivity",
    y = "Required Number of Trials") +
  theme_minimal()
```

## Dog and human

How many trials needed to determine dog performs better than human?

This is probably the better way to go, because the purpose of the study is to demonstrate that the dog is better than alternative methods - which in this case is human search. In other dog studies alternative methods might be, for example, live trapping or thermal camera imaging. 

Originally estimated at 80% for Koda and 30% for human, result of field trial was 100% for Koda and 40% for human.

```{r}
compare_sensitivity_power <- function(
  dog_sensitivity = 1,    # Expected dog sensitivity
  human_sensitivity = 0.4,  # Expected human sensitivity
  power = 0.8,              # Desired power )
  alpha = 0.05,             # Significance level
  alternative = "greater"   # One-sided dog > human
) {
  
  # Effect size calculation (h) for proportion test
  h <- ES.h(p1 = dog_sensitivity, p2 = human_sensitivity)
  
  # Calculate required sample size using pwr.2p.test
  # This function is for two proportions with equal sample sizes
  result <- pwr.2p.test(h = h, 
                        n = NULL,
                        sig.level = alpha, 
                        power = power,
                        alternative = alternative)
  
  # Return sample size (rounded up)
  # For pwr.2p.test, n1 = n2 = n (equal sample sizes)
  sample_size = ceiling(result$n)
  
  return(list(
    n1 = sample_size,  # Dog sample size
    n2 = sample_size   # Human sample size
  ))
}

# Create a function to explore different comparison scenarios
comparison_scenarios <- function(
  dog_sensitivities = seq(0.7, 1, by = 0.1),
  human_sensitivities = seq(0.2, 0.5, by = 0.1),
  power_values = c(0.8),
  alpha = 0.05
) {
  
  # Create a grid of all combinations
  scenarios <- expand_grid(
    dog_sensitivity = dog_sensitivities,
    human_sensitivity = human_sensitivities,
    power = power_values,
    alpha = alpha
  )
  
  # Calculate required sample size for each combination
  scenarios <- scenarios %>%
    rowwise() %>%
    mutate(
      sample_result = list(compare_sensitivity_power(
        dog_sensitivity = dog_sensitivity,
        human_sensitivity = human_sensitivity,
        power = power,
        alpha = alpha
      )),
      dog_sample = sample_result$n1,
      human_sample = sample_result$n2
    ) %>%
    select(-sample_result) %>%
    ungroup()
  
  return(scenarios)
}

# Generate dog vs human comparison scenarios
comparison <- comparison_scenarios()

# Create a visualization of the comparison scenarios
ggplot(comparison, 
       aes(x = human_sensitivity, y = dog_sample, label = dog_sample))+
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_text(hjust = 1.5, vjust = -0.5)+
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  xlim(c(0.15, 0.55))+
  ylim(c(0, 80))+
  labs(
    title = "Required Sample Size for Dog vs Human Sensitivity Comparison",
    subtitle = "Facet grouped by dog sensitivity",
    x = "Human Sensitivity",
    y = "Required Number of Trials (per group)",
    colour = "Human Sensitivity",
    linetype = "Statistical Power"
  ) +
  theme_bw()+
  facet_wrap(~dog_sensitivity)
```

# Statistics

## Summary stats

What were the sensitivity, precision and efficiency of the dog and human? Create confusion matrix to report results.

Definitions:

* Sensitivity: proportion of targets found relative to total number available
* Precision: proportion of alerts directed to a true target
* Efficiency: performance per unit effort

```{r}
# dog results, matrix and summary
dog_results <- read_xlsx("detection field test data.xlsx", sheet = "dog") %>%
  clean_names() %>%
  # convert NA strings to NAs
  mutate(across(where(is.character), ~na_if(., "NA"))) %>%
  # create binary expected and real values
  mutate(expected = as_factor(ifelse(type == "ABSENCE", 0, 1)),
         real = as_factor(ifelse(found == "TRUE", 1, 0))) %>%
  # omit excluded find, where "found" is NA
  drop_na(found)

dog_matrix <- confusionMatrix(data = dog_results$real, reference = dog_results$expected)

# calculate search time for presence searches only
search <- dog_results %>%
  filter(type == "PRESENCE") %>%
  summarise(mean = mean(search_time_s))

dog_summary <- data.frame(
  type = "dog",
  # true positive rate
  sensitivity = dog_matrix$byClass[1],
  # false positive rate
  precision = dog_matrix$byClass[5],
   # mean search time in minutes
  time = search$mean/60,
  row.names = NULL
) %>% mutate(
  # sensitivity divided by time, x 100 to be >0
  efficiency  = sensitivity / time * 100)

# human results, matrix and summary
human_results <- read_xlsx("detection field test data.xlsx", sheet = "human") %>%
  clean_names() %>%
  # convert NA strings to NAs
  mutate(across(where(is.character), ~na_if(., "NA"))) %>%
  # create binary real values
  mutate(real = as_factor(ifelse(found == "TRUE", 1, 0)))

human_matrix <- data.frame(
    true_pos = sum(human_results$real == 1),
    false_pos = 0,
    true_neg = NA,
    false_neg = sum(human_results$real == 0))

human_summary <- human_matrix %>%
  summarise(
    type = "human",
    # true positive rate
    sensitivity = true_pos / (true_pos + false_neg),
    # false positive rate
    precision = true_pos / (true_pos + false_pos),
    # mean search time in minutes
    time = mean(human_results$search_time_s)/60,
    # sensitivity divided by time, x 100 to be >0
    efficiency  = sensitivity / time * 100
  )

# both results
results <- rbind(dog_summary, human_summary)

results
```

## Time comparison

Is the dog significantly faster than the human-only searches?

```{r}
# combine times dataframe
dog_time <- dog_results %>%
  filter(type == "PRESENCE") %>%
  select(search_time_s) %>%
  mutate(type = "dog")

human_time <- human_results %>%
  select(search_time_s) %>%
  mutate(type = "human")

times <- rbind(dog_time, human_time) %>%
  rename(time = search_time_s)

# one sided t test
m1 <- t.test(time ~ type, data = times, alternative = "less")
m1

# approx 95% conf intervals using t distribution
conf <- times %>%
  group_by(type) %>%
  summarise(mean = mean(time),
            se = std.error(time),
            n = length(time)) %>%
  mutate(upper = (mean + qt(0.975, n-1) * se)/60,
         lower = (mean - qt(0.975, n-1) * se)/60)
```

Yes, the dog is significantly faster (p < 0.0001).

Plot search times.

```{r}
ggplot(times, aes(type, time/60))+
  geom_boxplot(aes(fill = type), alpha = 0.3, outlier.shape = NA)+
  geom_beeswarm(aes(colour = type), spacing = 1, method = "compactswarm")+
  scale_fill_manual(values = c("purple4", "seagreen4"), labels = c("Dog", "Human"))+
  scale_colour_manual(values = c("purple4", "seagreen4"), labels = c("Dog", "Human"))+
  ylab("Search time (min)")+
  xlab(NULL)+
  theme_classic()+
  theme(legend.position="none")

ggsave("search_times.png", height = 6, width = 6, units = "cm", dpi = 600)
```

